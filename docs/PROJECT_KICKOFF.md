# 📌 项目启动文档（Project Kickoff）

## 项目代号

**MirrorFlow**（暂定）

含义：多语言镜像内容流水线

> 名字可后期统一 branding，不影响技术推进

---

## 1️⃣ 项目背景 & 动机

### 背景

当前大量优质视频内容（访谈、演讲、播客、科技内容）存在明显的**语言壁垒**。

中文用户对海外内容存在巨大需求，但人工翻译 + 配音成本高、周期长、不可规模化。

与此同时：
- 本地 GPU（RTX 5080）算力充足
- Whisper / XTTS / Diarization 技术成熟
- YouTube 对「语言再创作内容」仍存在窗口期

### 核心动机

> 用本地 GPU + 自动化，把"视频语言转换"变成一条工业化流水线

---

## 2️⃣ 项目目标（明确 & 可验证）

### MVP 目标（第一阶段）

输入一个 YouTube 视频链接，自动完成：

1. 视频下载
2. 原音频转写（支持多人说话）
3. 翻译为自然中文
4. 区分说话人 → 多音色中文配音
5. 合成新视频（替换音轨）
6. 生成中文封面图 + 标题
7. 自动上传至 YouTube 频道（可选）

✅ **全流程无人干预**

---

## 3️⃣ 非目标（明确不做）

- ❌ 不做精确声纹克隆（规避法律风险）
- ❌ 不做影视剧 / 音乐内容
- ❌ 不做实时直播翻译（阶段一）

---

## 4️⃣ 用户 & 使用场景

### 目标用户（当前阶段）

- 自运营 YouTube 频道的创作者（你自己）
- 后续可扩展：MCN / 工作室 / 外包客户

### 使用方式

```
输入视频 URL
→ 等待 5–15 分钟
→ 获得可直接发布的中文配音视频
```

---

## 5️⃣ 总体技术架构

```
┌─────────┐
│  n8n    │  ← 流程编排 / 状态控制
└────┬────┘
     ↓
┌────────────────────────┐
│ Python Worker API       │
│ (FastAPI / Flask)       │
├────────────────────────┤
│ • Whisper Worker (GPU)  │
│ • Diarization Worker    │
│ • Translation Worker    │
│ • XTTS Worker (GPU)     │
│ • Video Mux Worker      │
│ • Thumbnail Worker      │
└────────────────────────┘
     ↓
 YouTube Upload / Local Output
```

### 设计原则

- n8n 不碰重计算
- GPU 资源集中在 Python Worker
- 各模块可独立替换 / 升级

---

## 6️⃣ 核心模块拆解

### 6.1 视频下载模块

- **工具**：yt-dlp
- **输出**：
  - `video.mp4`
  - `audio.wav`
- **异常处理**：
  - 下载失败 → 流程终止
  - 时长超限 → 拒绝或拆分

### 6.2 语音识别（ASR）

- **模型**：Whisper large-v3
- **运行方式**：CUDA（RTX 5080）
- **输出**：带时间戳的原语言字幕

```json
{
  "start": 12.3,
  "end": 15.8,
  "text": "This is an example"
}
```

### 6.3 说话人分离（Diarization）

- **模型**：pyannote.audio
- **输出**：字幕 + speaker label

```json
{
  "speaker": "SPEAKER_1",
  "start": 12.3,
  "end": 15.8,
  "text": "This is an example"
}
```

> 这是多音色配音的前提条件

### 6.4 翻译模块

- **初期方案**：API（稳定）
- **后期可选**：本地 LLM

**翻译要求**：
- 口语化
- 适合中文配音
- 不逐字翻译

### 6.5 中文配音（TTS）

- **模型**：XTTS v2
- **输入**：
  - 中文文本
  - 对应说话人的参考音频
- **输出**：
  - 按时间段生成的中文音频

**策略**：
- 每个 speaker 独立生成
- 音色稳定优先于"像原声"

### 6.6 音频对齐 & 视频合成

- **工具**：ffmpeg
- **视频编码**：NVENC（GPU）
- **行为**：
  - 替换原音轨
  - 保留原画面

### 6.7 封面生成

- **模型**：SDXL / Flux
- **输入**：
  - 视频摘要
  - 情绪关键词
- **输出**：
  - 1280×720 JPG/PNG

### 6.8 标题 / 描述生成

LLM 生成：
- 强吸睛标题
- 稳妥标题
- 描述
- Tags

### 6.9 YouTube 上传（可选）

- **YouTube Data API v3**
- **支持**：
  - 自动上传
  - 定时发布
  - 封面设置

---

## 7️⃣ 数据结构（核心）

```
job/
 ├── source/
 │   ├── video.mp4
 │   └── audio.wav
 ├── transcript/
 │   ├── raw.json
 │   └── diarized.json
 ├── translation/
 │   └── zh.json
 ├── tts/
 │   ├── speaker_1.wav
 │   └── speaker_2.wav
 ├── output/
 │   └── final_video.mp4
 └── meta.json
```

---

## 8️⃣ 硬件 & 环境要求

### 硬件

| 组件 | 要求 |
|------|------|
| GPU | RTX 5080（主算力） |
| CPU | 8 核以上 |
| 内存 | 32GB+ |
| 存储 | NVMe SSD |

### 软件

- OS：Ubuntu 22.04
- CUDA / cuDNN
- Python 3.10+
- ffmpeg（支持 NVENC）

---

## 9️⃣ 风险 & 合规边界

### 版权

- 仅用于**语言转换 + 再创作**
- 明显不同封面 / 标题
- 不使用原字幕、不复刻原音轨

### 声音

- 禁止精确声纹克隆
- 使用"相似风格"即可

---

## 🔟 里程碑（建议）

### Phase 1：核心链路（7–10 天）

- [ ] Whisper + Diarization
- [ ] XTTS 配音
- [ ] 视频合成

### Phase 2：自动化（5 天）

- [ ] n8n 串流程
- [ ] 错误恢复
- [ ] 批量处理

### Phase 3：内容化（可选）

- [ ] 封面模板
- [ ] 标题策略
- [ ] 多频道扩展

---

## 1️⃣1️⃣ 成功标准（Definition of Done）

- ✅ 一条 10–20 分钟访谈视频
- ✅ 两个说话人 → 两种中文音色
- ✅ 无明显时间错位
- ✅ 可直接上传 YouTube
- ✅ 全程无人操作
