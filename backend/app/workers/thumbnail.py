"""Thumbnail generation worker for YouTube-style video covers.

Uses video screenshots (not AI-generated images) for authenticity.
"""

import hashlib
import httpx
import io
import subprocess
from pathlib import Path
from typing import Optional, Tuple, List
from loguru import logger

from app.config import settings

# YouTube thumbnail dimensions
YOUTUBE_WIDTH = 1280
YOUTUBE_HEIGHT = 720


class ThumbnailWorker:
    """Worker for generating YouTube-style video thumbnails from video frames."""

    def __init__(self):
        self.api_key = settings.llm_api_key
        self.base_url = settings.llm_base_url
        self.enabled = bool(self.api_key)

    async def analyze_emotional_moments(
        self,
        subtitles: List[dict],
    ) -> Tuple[float, str]:
        """Analyze subtitles to find the most dramatic/emotional moment.

        Args:
            subtitles: List of subtitle dicts with 'start', 'end', 'en' keys

        Returns:
            Tuple of (timestamp, reason) for the most eye-catching moment
        """
        # Format subtitles for analysis
        subtitle_text = "\n".join([
            f"[{s.get('start', 0):.1f}s] {s.get('en', s.get('text', ''))}"
            for s in subtitles[:50]  # Analyze first 50 segments
        ])

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªè§†é¢‘å°é¢è®¾è®¡ä¸“å®¶ã€‚åˆ†æžè§†é¢‘å°è¯ï¼Œæ‰¾å‡ºæœ€é€‚åˆåšå°é¢çš„é‚£ä¸€åˆ»ã€‚

å¯»æ‰¾ä»¥ä¸‹ç±»åž‹çš„æ—¶åˆ»ï¼š
- å†²çªã€å¯¹æŠ—ã€äº‰è®º
- éœ‡æƒŠã€æƒŠè®¶çš„ååº”
- é‡è¦å®£å¸ƒã€å£°æ˜Ž
- æƒ…ç»ªæ¿€åŠ¨çš„è¡¨è¾¾
- æœ‰äº‰è®®æ€§çš„è¨€è®º

è¿”å›žJSONæ ¼å¼ï¼š
{"timestamp": ç§’æ•°, "reason": "ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªæ—¶åˆ»"}

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        user_prompt = f"""åˆ†æžä»¥ä¸‹å°è¯ï¼Œæ‰¾å‡ºæœ€é€‚åˆåšYouTubeå°é¢çš„æ—¶åˆ»ï¼š

{subtitle_text}

é€‰æ‹©æœ€åšçœ¼çƒã€æœ€æœ‰å†²å‡»åŠ›çš„é‚£ä¸€åˆ»ï¼š"""

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{settings.llm_base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": settings.llm_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        "max_tokens": 150,
                        "temperature": 0.7,
                    },
                )
                response.raise_for_status()
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()

                # Parse JSON response
                import json
                if "```" in content:
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]

                result = json.loads(content)
                timestamp = float(result.get("timestamp", 10))
                reason = result.get("reason", "")

                logger.info(f"Selected moment at {timestamp}s: {reason}")
                return timestamp, reason

        except Exception as e:
            logger.error(f"Failed to analyze emotional moments: {e}")
            # Default to 10 seconds into the video
            return 10.0, "Default selection"

    async def generate_clickbait_title(
        self,
        title: str,
        subtitles: List[dict],
    ) -> Tuple[str, str]:
        """Generate clickbait Chinese titles for thumbnail.

        Args:
            title: Video title
            subtitles: List of subtitle dicts

        Returns:
            Tuple of (main_title, sub_title) in Chinese
        """
        content_sample = " ".join([
            s.get('en', s.get('text', '')) for s in subtitles[:15]
        ])[:800]

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªYouTubeè§†é¢‘å°é¢æ ‡é¢˜è®¾è®¡å¸ˆã€‚æ ¹æ®è§†é¢‘å†…å®¹ç”Ÿæˆä¸¤è¡Œåšçœ¼çƒçš„ä¸­æ–‡æ ‡é¢˜ã€‚

è§„åˆ™ï¼š
- ä¸»æ ‡é¢˜ï¼š6-10ä¸ªå­—ï¼Œé»„è‰²å¤§å­—ï¼Œè¦éœ‡æ’¼ã€å¸å¼•ç‚¹å‡»
- å‰¯æ ‡é¢˜ï¼š6-12ä¸ªå­—ï¼Œç™½è‰²å¤§å­—ï¼Œè¡¥å……è¯´æ˜Ž
- é£Žæ ¼ï¼šæ–°é—»å¤´æ¡ã€éœ‡æ’¼ã€å¼•å‘å¥½å¥‡
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- å¯ä»¥ç¨å¾®å¤¸å¼ ä½†ä¸è¦è™šå‡

ç¤ºä¾‹ï¼š
ä¸»æ ‡é¢˜ï¼šä½ å°±æ˜¯å·¦ç¿¼èµ°ç‹—
å‰¯æ ‡é¢˜ï¼šä¸Šä»»ä¾†æœ€å¤§è¡çª

ä¸»æ ‡é¢˜ï¼šå·æ™®éœ‡æ€’é–‹é™¤
å‰¯æ ‡é¢˜ï¼šFBIå±€é•·ç•¶å ´å‚»çœ¼

åªè¾“å‡ºJSONæ ¼å¼ï¼š
{"main": "ä¸»æ ‡é¢˜", "sub": "å‰¯æ ‡é¢˜"}"""

        user_prompt = f"""è§†é¢‘æ ‡é¢˜ï¼š{title}

è§†é¢‘å†…å®¹æ‘˜è¦ï¼š{content_sample}

ç”Ÿæˆåšçœ¼çƒçš„ä¸­æ–‡å°é¢æ ‡é¢˜ï¼š"""

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{settings.llm_base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": settings.llm_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        "max_tokens": 200,
                        "temperature": 0.9,
                    },
                )
                response.raise_for_status()
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()

                # Parse JSON response
                import json
                if "```" in content:
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]

                titles = json.loads(content)
                return titles.get("main", "ç²¾å½©å…§å®¹"), titles.get("sub", "ä¸å®¹éŒ¯éŽ")

        except Exception as e:
            logger.error(f"Failed to generate clickbait title: {e}")
            return "ç²¾å½©å…§å®¹", "ä¸å®¹éŒ¯éŽ"

    async def generate_youtube_metadata(
        self,
        title: str,
        subtitles: List[dict],
        source_url: Optional[str] = None,
        duration: Optional[float] = None,
    ) -> dict:
        """Generate SEO-optimized YouTube metadata (title, description, tags).

        Args:
            title: Original video title
            subtitles: List of subtitle dicts
            source_url: Original video URL
            duration: Video duration in seconds

        Returns:
            Dict with 'title', 'description', 'tags' keys
        """
        # Get content sample from subtitles
        content_sample = " ".join([
            s.get('en', s.get('text', '')) for s in subtitles[:30]
        ])[:1500]

        # Format duration for description
        duration_str = ""
        if duration:
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            if hours > 0:
                duration_str = f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
            else:
                duration_str = f"{minutes}åˆ†é’Ÿ"

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªYouTube SEOä¸“å®¶ã€‚æ ¹æ®è§†é¢‘å†…å®¹ç”Ÿæˆèƒ½æœ€å¤§åŒ–æ›å…‰é‡çš„å…ƒæ•°æ®ã€‚

**ä»»åŠ¡ï¼šç”ŸæˆYouTube SEOä¼˜åŒ–çš„æ ‡é¢˜ã€æè¿°å’Œæ ‡ç­¾**

## æ ‡é¢˜è§„åˆ™ï¼š
- é•¿åº¦ï¼š40-70ä¸ªå­—ç¬¦ï¼ˆä¸­æ–‡çº¦20-35å­—ï¼‰
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- åŒ…å«æ ¸å¿ƒå…³é”®è¯
- å¸å¼•ç‚¹å‡»ä½†ä¸è™šå‡
- å¯åŠ å…¥æ•°å­—ã€é—®å·ã€æƒŠå¹å·å¢žåŠ å¸å¼•åŠ›
- ç¤ºä¾‹ï¼šã€Œå·æ™®2025æ–°æ”¿ç­–éœ‡é©šå…¨çƒï¼å°ˆå®¶è§£è®€5å¤§å½±éŸ¿ã€

## æè¿°è§„åˆ™ï¼š
- ç¬¬ä¸€è¡Œï¼šæ ¸å¿ƒå†…å®¹æ‘˜è¦ï¼ˆä¼šæ˜¾ç¤ºåœ¨æœç´¢ç»“æžœï¼‰
- åŒ…å«3-5ä¸ªæ ¸å¿ƒå…³é”®è¯
- æ·»åŠ æ—¶é—´æˆ³ï¼ˆå¦‚æžœå¯èƒ½ï¼‰
- åŒ…å«è¡ŒåŠ¨å·å¬ï¼ˆè®¢é˜…ã€ç‚¹èµžã€è¯„è®ºï¼‰
- æ·»åŠ ç›¸å…³ #hashtag
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- é•¿åº¦ï¼š200-500å­—

## æ ‡ç­¾è§„åˆ™ï¼š
- 15-25ä¸ªç›¸å…³æ ‡ç­¾
- æ··åˆï¼šæ ¸å¿ƒå…³é”®è¯ + é•¿å°¾å…³é”®è¯ + çƒ­é—¨è¯é¢˜
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡å’Œè‹±æ–‡æ ‡ç­¾
- é¿å…æ— å…³æ ‡ç­¾

è¾“å‡ºJSONæ ¼å¼ï¼š
{
  "title": "SEOä¼˜åŒ–çš„æ ‡é¢˜",
  "description": "å®Œæ•´çš„æè¿°ï¼ˆåŒ…å«hashtagï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", ...]
}

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        user_prompt = f"""åŽŸè§†é¢‘æ ‡é¢˜ï¼š{title}

è§†é¢‘å†…å®¹æ‘˜è¦ï¼š
{content_sample}

{f"è§†é¢‘æ—¶é•¿ï¼š{duration_str}" if duration_str else ""}
{f"åŽŸå§‹é“¾æŽ¥ï¼š{source_url}" if source_url else ""}

è¯·ç”ŸæˆSEOä¼˜åŒ–çš„YouTubeå…ƒæ•°æ®ï¼š"""

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{settings.llm_base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": settings.llm_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        "max_tokens": 1500,
                        "temperature": 0.7,
                    },
                )
                response.raise_for_status()
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()

                # Parse JSON response
                import json
                if "```" in content:
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]

                result = json.loads(content)
                logger.info(f"Generated YouTube metadata: title={result.get('title', '')[:30]}...")
                return {
                    "title": result.get("title", title),
                    "description": result.get("description", f"Original: {source_url or 'N/A'}"),
                    "tags": result.get("tags", ["learning", "english", "chinese"]),
                }

        except Exception as e:
            logger.error(f"Failed to generate YouTube metadata: {e}")
            return {
                "title": title,
                "description": f"Original: {source_url or 'N/A'}",
                "tags": ["learning", "english", "chinese"],
            }

    async def generate_unified_metadata(
        self,
        title: str,
        subtitles: List[dict],
        source_url: Optional[str] = None,
        duration: Optional[float] = None,
        num_title_candidates: int = 5,
        user_instruction: Optional[str] = None,
    ) -> dict:
        """Generate coordinated YouTube metadata and thumbnail title candidates together.

        This ensures the YouTube title and thumbnail titles are consistent and
        follow the same user instruction.

        Args:
            title: Original video title
            subtitles: List of subtitle dicts
            source_url: Original video URL
            duration: Video duration in seconds
            num_title_candidates: Number of thumbnail title candidates
            user_instruction: Optional user instruction to guide generation

        Returns:
            Dict with 'youtube' (title, description, tags) and 'thumbnail_candidates' (list)
        """
        content_sample = " ".join([
            s.get('en', s.get('text', '')) for s in subtitles[:30]
        ])[:1500]

        # Format duration for description
        duration_str = ""
        if duration:
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            if hours > 0:
                duration_str = f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
            else:
                duration_str = f"{minutes}åˆ†é’Ÿ"

        # Log the instruction for debugging
        if user_instruction:
            logger.info(f"Generating metadata with user instruction: {user_instruction}")
        else:
            logger.info("Generating metadata without user instruction")

        # Build instruction section - placed prominently in user prompt for better adherence
        instruction_block = ""
        if user_instruction:
            instruction_block = f"""
âš ï¸ **ç”¨æˆ·åˆ›ä½œæŒ‡å¯¼ - æœ€é«˜ä¼˜å…ˆçº§ï¼Œå¿…é¡»ä¸¥æ ¼éµå¾ªï¼** âš ï¸
ã€Œ{user_instruction}ã€

ä½ å¿…é¡»æ ¹æ®ä¸Šè¿°æŒ‡å¯¼æ¥åˆ›ä½œå†…å®¹ã€‚æ ‡é¢˜å’Œæè¿°å¿…é¡»å›´ç»•ç”¨æˆ·æŒ‡å®šçš„ä¸»é¢˜/è§’åº¦ã€‚
å¦‚æžœç”¨æˆ·æŒ‡å®šäº†"çªå‡ºå†²çª"ï¼Œæ ‡é¢˜å¿…é¡»ä½“çŽ°å†²çªï¼›å¦‚æžœæŒ‡å®šäº†"æŸä¸ªè¯é¢˜"ï¼Œå¿…é¡»ä»¥è¯¥è¯é¢˜ä¸ºæ ¸å¿ƒã€‚
---

"""

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªYouTubeå†…å®¹ä¼˜åŒ–ä¸“å®¶ã€‚æ ¹æ®è§†é¢‘å†…å®¹ç”Ÿæˆ**åè°ƒä¸€è‡´**çš„YouTubeå…ƒæ•°æ®å’Œå°é¢æ ‡é¢˜ã€‚

**é‡è¦ï¼šYouTubeæ ‡é¢˜å’Œå°é¢æ ‡é¢˜å¿…é¡»ä¸»é¢˜ä¸€è‡´ã€é£Žæ ¼åè°ƒï¼**

## ä»»åŠ¡1ï¼šYouTubeå…ƒæ•°æ®

### æ ‡é¢˜è§„åˆ™ï¼š
- é•¿åº¦ï¼š40-70ä¸ªå­—ç¬¦ï¼ˆä¸­æ–‡çº¦20-35å­—ï¼‰
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- åŒ…å«æ ¸å¿ƒå…³é”®è¯
- å¸å¼•ç‚¹å‡»ä½†ä¸è™šå‡

### æè¿°è§„åˆ™ï¼ˆéžå¸¸é‡è¦ï¼ï¼‰ï¼š
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- **å¿…é¡»åŒ…å«æ—¶é—´çº¿ç« èŠ‚æ ‡è®°**ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
  â° æ™‚é–“ç·š
  00:00 é–‹å ´ç™½
  02:30 ç¬¬ä¸€å€‹é‡é»ž
  05:45 ç¬¬äºŒå€‹é‡é»ž
  ...
- **ç»“æž„è¦æ±‚**ï¼š
  1. ç¬¬ä¸€æ®µï¼šæ ¸å¿ƒå†…å®¹æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰
  2. ç¬¬äºŒæ®µï¼šæ™‚é–“ç·šï¼ˆâ°æ ‡è®°ï¼Œè‡³å°‘5-8ä¸ªæ—¶é—´ç‚¹ï¼Œæ ¹æ®è§†é¢‘å†…å®¹åˆ†å—ï¼‰
  3. ç¬¬ä¸‰æ®µï¼šå…³é”®è¯æ ‡ç­¾ï¼ˆ#hashtagæ ¼å¼ï¼‰
  4. ç¬¬å››æ®µï¼šè¡ŒåŠ¨å·å¬ï¼ˆè®¢é˜…ã€ç‚¹èµžã€å¼€å¯å°é“ƒé“›ï¼‰
  5. æœ€åŽå¿…é¡»åŒ…å«ï¼š
     ---
     ðŸ“º åŽŸå½±ç‰‡ï¼š{{source_url}}
     âš ï¸ æœ¬å½±ç‰‡åƒ…ä¾›å­¸ç¿’äº¤æµä½¿ç”¨ï¼Œç‰ˆæ¬Šæ­¸åŽŸä½œè€…æ‰€æœ‰ã€‚å¦‚æœ‰ä¾µæ¬Šè«‹è¯ç¹«åˆªé™¤ã€‚
- é•¿åº¦ï¼š400-800å­—

### æ ‡ç­¾è§„åˆ™ï¼š
- 15-25ä¸ªç›¸å…³æ ‡ç­¾
- æ··åˆç¹ä½“ä¸­æ–‡å’Œè‹±æ–‡

## ä»»åŠ¡2ï¼šå°é¢æ ‡é¢˜å€™é€‰ï¼ˆ{num_title_candidates}ç»„ï¼‰

### æ¯ç»„åŒ…å«ï¼š
- main: ä¸»æ ‡é¢˜ï¼ˆ6-10å­—ï¼Œé»„è‰²å¤§å­—ï¼‰
- sub: å‰¯æ ‡é¢˜ï¼ˆ6-12å­—ï¼Œç™½è‰²å­—ï¼‰
- style: é£Žæ ¼æè¿°

### è§„åˆ™ï¼š
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- é£Žæ ¼å¤šæ ·åŒ–ï¼šéœ‡æ’¼åž‹ã€æ‚¬å¿µåž‹ã€å¯¹æŠ—åž‹ã€æƒ…æ„Ÿåž‹ã€æ­ç§˜åž‹
- **å¿…é¡»ä¸ŽYouTubeæ ‡é¢˜ä¸»é¢˜ä¸€è‡´**

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "youtube": {{
    "title": "YouTubeæ ‡é¢˜",
    "description": "å®Œæ•´æè¿°",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", ...]
  }},
  "thumbnail_candidates": [
    {{"main": "ä¸»æ ‡é¢˜1", "sub": "å‰¯æ ‡é¢˜1", "style": "éœ‡æ’¼åž‹"}},
    {{"main": "ä¸»æ ‡é¢˜2", "sub": "å‰¯æ ‡é¢˜2", "style": "æ‚¬å¿µåž‹"}},
    ...
  ]
}}

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        # Format subtitles with timestamps for timeline generation
        subtitle_timeline = "\n".join([
            f"[{int(s.get('start', 0) // 60):02d}:{int(s.get('start', 0) % 60):02d}] {s.get('en', s.get('text', ''))[:80]}"
            for s in subtitles[:60]  # Include more segments for better chapter detection
        ])

        user_prompt = f"""{instruction_block}åŽŸè§†é¢‘æ ‡é¢˜ï¼š{title}

{f"è§†é¢‘æ—¶é•¿ï¼š{duration_str}" if duration_str else ""}
{f"åŽŸå§‹é“¾æŽ¥ï¼ˆå¿…é¡»åŒ…å«åœ¨æè¿°æœ€åŽï¼‰ï¼š{source_url}" if source_url else ""}

è§†é¢‘å°è¯ï¼ˆå¸¦æ—¶é—´æˆ³ï¼Œç”¨äºŽç”Ÿæˆæ—¶é—´çº¿ç« èŠ‚ï¼‰ï¼š
{subtitle_timeline}

è§†é¢‘å†…å®¹æ‘˜è¦ï¼š
{content_sample}

è¯·ç”Ÿæˆåè°ƒä¸€è‡´çš„YouTubeå…ƒæ•°æ®å’Œ{num_title_candidates}ç»„å°é¢æ ‡é¢˜å€™é€‰ã€‚
**æè¿°ä¸­å¿…é¡»åŒ…å«æ—¶é—´çº¿ç« èŠ‚ï¼ˆæ ¹æ®å°è¯å†…å®¹åˆ†å—ï¼‰ã€åŽŸè§†é¢‘é“¾æŽ¥ã€ç‰ˆæƒå£°æ˜Žï¼**
{f" **è¯·åŠ¡å¿…å›´ç»•ç”¨æˆ·æŒ‡å¯¼ã€Œ{user_instruction}ã€æ¥åˆ›ä½œï¼**" if user_instruction else ""}"""

        # Lower temperature when user provides instruction for better adherence
        temperature = 0.6 if user_instruction else 0.85

        try:
            async with httpx.AsyncClient(timeout=90.0) as client:
                response = await client.post(
                    f"{settings.llm_base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": settings.llm_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        "max_tokens": 2000,
                        "temperature": temperature,
                    },
                )
                response.raise_for_status()
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()

                # Parse JSON response
                import json
                if "```" in content:
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]

                result = json.loads(content)

                # Format thumbnail candidates
                candidates = []
                for i, c in enumerate(result.get("thumbnail_candidates", [])[:num_title_candidates]):
                    candidates.append({
                        "index": i,
                        "main": c.get("main", "ç²¾å½©å…§å®¹"),
                        "sub": c.get("sub", "ä¸å®¹éŒ¯éŽ"),
                        "style": c.get("style", ""),
                    })

                youtube = result.get("youtube", {})
                logger.info(f"Generated unified metadata: YouTube title={youtube.get('title', '')[:30]}...")

                return {
                    "youtube": {
                        "title": youtube.get("title", title),
                        "description": youtube.get("description", f"Original: {source_url or 'N/A'}"),
                        "tags": youtube.get("tags", ["learning", "english", "chinese"]),
                    },
                    "thumbnail_candidates": candidates,
                }

        except Exception as e:
            logger.error(f"Failed to generate unified metadata: {e}")
            # Return defaults
            return {
                "youtube": {
                    "title": title,
                    "description": f"Original: {source_url or 'N/A'}",
                    "tags": ["learning", "english", "chinese"],
                },
                "thumbnail_candidates": [
                    {"index": 0, "main": "ç²¾å½©å…§å®¹", "sub": "ä¸å®¹éŒ¯éŽ", "style": "é»˜è®¤"},
                ],
            }

    async def generate_title_candidates(
        self,
        title: str,
        subtitles: List[dict],
        num_candidates: int = 5,
        user_instruction: Optional[str] = None,
    ) -> List[dict]:
        """Generate multiple title candidates for user selection.

        Args:
            title: Video title
            subtitles: List of subtitle dicts
            num_candidates: Number of candidates to generate
            user_instruction: Optional user instruction to guide title generation

        Returns:
            List of dicts with 'main' and 'sub' keys
        """
        content_sample = " ".join([
            s.get('en', s.get('text', '')) for s in subtitles[:20]
        ])[:1000]

        # Build instruction section - make it prominent if provided
        instruction_section = ""
        user_instruction_reminder = ""
        if user_instruction:
            instruction_section = f"""
**ã€ç”¨æˆ·åˆ›ä½œæŒ‡å¯¼ - å¿…é¡»éµå¾ªã€‘**
{user_instruction}
---
"""
            user_instruction_reminder = f"\n\n**é‡è¦ï¼šæ ‡é¢˜å¿…é¡»å›´ç»•ç”¨æˆ·æŒ‡å¯¼ã€Œ{user_instruction}ã€æ¥åˆ›ä½œï¼**"

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªYouTubeè§†é¢‘å°é¢æ ‡é¢˜è®¾è®¡å¸ˆã€‚æ ¹æ®è§†é¢‘å†…å®¹ç”Ÿæˆ{num_candidates}ç»„ä¸åŒé£Žæ ¼çš„åšçœ¼çƒä¸­æ–‡æ ‡é¢˜ã€‚
{instruction_section}
è§„åˆ™ï¼š
- æ¯ç»„åŒ…å«ä¸»æ ‡é¢˜ï¼ˆ6-10å­—ï¼‰å’Œå‰¯æ ‡é¢˜ï¼ˆ6-12å­—ï¼‰
- ä½¿ç”¨ç¹ä½“ä¸­æ–‡
- é£Žæ ¼è¦å¤šæ ·åŒ–ï¼šéœ‡æ’¼åž‹ã€æ‚¬å¿µåž‹ã€å¯¹æŠ—åž‹ã€æƒ…æ„Ÿåž‹ã€æ­ç§˜åž‹
- å¯ä»¥ç¨å¾®å¤¸å¼ ä½†ä¸è¦è™šå‡
- è¦æŠ“ä½è§†é¢‘æ ¸å¿ƒäº®ç‚¹

è¾“å‡ºJSONæ•°ç»„æ ¼å¼ï¼š
[
  {{"main": "ä¸»æ ‡é¢˜1", "sub": "å‰¯æ ‡é¢˜1", "style": "é£Žæ ¼æè¿°"}},
  {{"main": "ä¸»æ ‡é¢˜2", "sub": "å‰¯æ ‡é¢˜2", "style": "é£Žæ ¼æè¿°"}},
  ...
]"""

        user_prompt = f"""è§†é¢‘æ ‡é¢˜ï¼š{title}

è§†é¢‘å†…å®¹æ‘˜è¦ï¼š{content_sample}

ç”Ÿæˆ{num_candidates}ç»„ä¸åŒé£Žæ ¼çš„å°é¢æ ‡é¢˜ï¼š{user_instruction_reminder}"""

        # Lower temperature when user provides instruction for better adherence
        temperature = 0.7 if user_instruction else 1.0

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{settings.llm_base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": settings.llm_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        "max_tokens": 800,
                        "temperature": temperature,
                    },
                )
                response.raise_for_status()
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()

                # Parse JSON response
                import json
                if "```" in content:
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]

                candidates = json.loads(content)

                # Ensure we have the required fields
                result = []
                for i, c in enumerate(candidates[:num_candidates]):
                    result.append({
                        "index": i,
                        "main": c.get("main", "ç²¾å½©å…§å®¹"),
                        "sub": c.get("sub", "ä¸å®¹éŒ¯éŽ"),
                        "style": c.get("style", ""),
                    })

                logger.info(f"Generated {len(result)} title candidates")
                return result

        except Exception as e:
            logger.error(f"Failed to generate title candidates: {e}")
            # Return default candidates
            return [
                {"index": 0, "main": "ç²¾å½©å…§å®¹", "sub": "ä¸å®¹éŒ¯éŽ", "style": "é»˜è®¤"},
            ]

    def get_video_duration(self, video_path: Path) -> Optional[float]:
        """Get video duration in seconds using ffprobe.

        Args:
            video_path: Path to video file

        Returns:
            Duration in seconds or None if failed
        """
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(video_path),
        ]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                return float(result.stdout.strip())
        except Exception as e:
            logger.error(f"Failed to get video duration: {e}")
        return None

    def extract_candidate_frames(
        self,
        video_path: Path,
        output_dir: Path,
        num_candidates: int = 6,
        duration: Optional[float] = None,
    ) -> List[dict]:
        """Extract multiple candidate frames at different timestamps.

        Args:
            video_path: Path to video file
            output_dir: Directory to save frames
            num_candidates: Number of candidates to generate (default 6)
            duration: Video duration (will be auto-detected if not provided)

        Returns:
            List of dicts with 'timestamp', 'path', 'filename', 'url' keys
        """
        video_path = Path(video_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if duration is None:
            duration = self.get_video_duration(video_path)
            if duration is None:
                logger.error("Could not determine video duration")
                return []

        # Generate timestamps at evenly distributed points (avoiding very start/end)
        # e.g., for 6 candidates: 10%, 25%, 40%, 55%, 70%, 85%
        candidates = []
        for i in range(num_candidates):
            pct = 0.10 + (i * 0.75 / (num_candidates - 1))  # 10% to 85%
            timestamp = duration * pct

            filename = f"candidate_{i+1}_{int(timestamp)}s.jpg"
            output_path = output_dir / filename

            result = self.extract_frame(video_path, timestamp, output_path)
            if result:
                candidates.append({
                    "index": i + 1,
                    "timestamp": round(timestamp, 2),
                    "path": str(output_path),
                    "filename": filename,
                })
                logger.info(f"Extracted candidate {i+1} at {timestamp:.1f}s")

        return candidates

    def extract_frame(
        self,
        video_path: Path,
        timestamp: float,
        output_path: Path,
    ) -> Optional[Path]:
        """Extract a frame from video at given timestamp.

        Args:
            video_path: Path to video file
            timestamp: Time in seconds
            output_path: Where to save the frame

        Returns:
            Path to extracted frame or None if failed
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        cmd = [
            "ffmpeg",
            "-ss", str(timestamp),
            "-i", str(video_path),
            "-vframes", "1",
            "-q:v", "2",  # High quality JPEG
            "-y",  # Overwrite
            str(output_path),
        ]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode != 0:
                logger.error(f"FFmpeg error: {result.stderr}")
                return None

            if output_path.exists():
                logger.info(f"Extracted frame at {timestamp}s: {output_path}")
                return output_path
            else:
                logger.error("Frame extraction completed but file not found")
                return None

        except subprocess.TimeoutExpired:
            logger.error("FFmpeg timeout")
            return None
        except Exception as e:
            logger.exception(f"Failed to extract frame: {e}")
            return None

    def add_text_overlay(
        self,
        image_path: Path,
        main_title: str,
        sub_title: str,
    ) -> bytes:
        """Add text overlays to the thumbnail image.

        Args:
            image_path: Path to base image
            main_title: Main title (yellow text)
            sub_title: Sub title (white text on blue bar)

        Returns:
            Final image bytes (with "ä¸­è‹±å­—å¹•" badge in top-left)
        """
        from PIL import Image, ImageDraw, ImageFont, ImageEnhance
        import os

        # Load and resize image
        img = Image.open(image_path)
        img = img.resize((YOUTUBE_WIDTH, YOUTUBE_HEIGHT), Image.Resampling.LANCZOS)

        # Slightly increase contrast for more dramatic look
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.1)

        draw = ImageDraw.Draw(img)

        # Try to load Chinese font
        font_paths = [
            # Docker / Ubuntu (fonts-noto-cjk package)
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            # macOS
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/STHeiti Light.ttc",
            "/Library/Fonts/Arial Unicode.ttf",
            # Windows
            "C:\\Windows\\Fonts\\msyh.ttc",
            "C:\\Windows\\Fonts\\simhei.ttf",
        ]

        def load_font(size: int) -> ImageFont.FreeTypeFont:
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        return ImageFont.truetype(font_path, size)
                    except Exception:
                        continue
            return ImageFont.load_default()

        def get_font_to_fit(text: str, max_width: int, max_size: int, min_size: int = 40) -> ImageFont.FreeTypeFont:
            """Find the largest font size that fits the text within max_width."""
            for size in range(max_size, min_size - 1, -5):
                font = load_font(size)
                bbox = draw.textbbox((0, 0), text, font=font)
                text_width = bbox[2] - bbox[0]
                if text_width <= max_width:
                    return font
            return load_font(min_size)

        # Calculate available width with padding
        padding = 40  # 20px on each side
        available_width = YOUTUBE_WIDTH - padding * 2

        # Fonts - dynamically sized to fit
        main_font = get_font_to_fit(main_title, available_width, max_size=140, min_size=60)
        sub_font = get_font_to_fit(sub_title, available_width, max_size=100, min_size=40)
        badge_font = load_font(42)

        # Colors
        yellow = (255, 255, 0)
        white = (255, 255, 255)
        blue = (0, 120, 200)
        black_outline = (0, 0, 0)

        def draw_text_with_outline(
            draw: ImageDraw.Draw,
            position: Tuple[int, int],
            text: str,
            font: ImageFont.FreeTypeFont,
            fill_color: Tuple[int, int, int],
            outline_color: Tuple[int, int, int] = black_outline,
            outline_width: int = 3,
        ):
            """Draw text with outline for better visibility."""
            x, y = position
            for dx in range(-outline_width, outline_width + 1):
                for dy in range(-outline_width, outline_width + 1):
                    if dx != 0 or dy != 0:
                        draw.text((x + dx, y + dy), text, font=font, fill=outline_color)
            draw.text(position, text, font=font, fill=fill_color)

        # Draw main title (yellow, center area - large and impactful)
        main_bbox = draw.textbbox((0, 0), main_title, font=main_font)
        main_width = main_bbox[2] - main_bbox[0]
        main_height = main_bbox[3] - main_bbox[1]
        main_x = (YOUTUBE_WIDTH - main_width) // 2
        main_y = YOUTUBE_HEIGHT - 300  # Higher position for larger text

        draw_text_with_outline(draw, (main_x, main_y), main_title, main_font, yellow, outline_width=6)

        # Draw blue bar at bottom (taller for larger text)
        bar_height = 130
        bar_y = YOUTUBE_HEIGHT - bar_height
        draw.rectangle([(0, bar_y), (YOUTUBE_WIDTH, YOUTUBE_HEIGHT)], fill=blue)

        # Draw sub title (white on blue bar)
        sub_bbox = draw.textbbox((0, 0), sub_title, font=sub_font)
        sub_width = sub_bbox[2] - sub_bbox[0]
        sub_x = (YOUTUBE_WIDTH - sub_width) // 2
        sub_y = bar_y + (bar_height - (sub_bbox[3] - sub_bbox[1])) // 2 - 8

        draw.text((sub_x, sub_y), sub_title, font=sub_font, fill=white)

        # Draw corner badge (top-left) - two lines: "ä¸­è‹±" / "å­—å¹•"
        badge_line1 = "ä¸­è‹±"
        badge_line2 = "å­—å¹•"
        badge_padding_x = 16
        badge_padding_y = 12
        line_spacing = 6

        bbox1 = draw.textbbox((0, 0), badge_line1, font=badge_font)
        bbox2 = draw.textbbox((0, 0), badge_line2, font=badge_font)
        line1_width = bbox1[2] - bbox1[0]
        line2_width = bbox2[2] - bbox2[0]
        line_height = bbox1[3] - bbox1[1]

        badge_width = max(line1_width, line2_width) + badge_padding_x * 2
        badge_height = line_height * 2 + line_spacing + badge_padding_y * 2

        draw.rectangle([(20, 20), (20 + badge_width, 20 + badge_height)], fill=yellow)
        # Center each line horizontally
        line1_x = 20 + (badge_width - line1_width) // 2
        line2_x = 20 + (badge_width - line2_width) // 2
        draw.text((line1_x, 20 + badge_padding_y), badge_line1, font=badge_font, fill=(0, 0, 0))
        draw.text((line2_x, 20 + badge_padding_y + line_height + line_spacing), badge_line2, font=badge_font, fill=(0, 0, 0))

        # Save to bytes
        output = io.BytesIO()
        img.save(output, format="PNG", quality=95)
        return output.getvalue()

    async def generate_from_frame(
        self,
        title: str,
        subtitles: List[dict],
        frame_path: Path,
        output_dir: Path,
        filename: Optional[str] = None,
        main_title: Optional[str] = None,
        sub_title: Optional[str] = None,
    ) -> Optional[Path]:
        """Generate thumbnail from an existing frame image.

        Args:
            title: Video title (used for generating titles if not provided)
            subtitles: List of subtitle dicts (used for generating titles if not provided)
            frame_path: Path to source frame image
            output_dir: Directory to save thumbnail
            filename: Optional filename
            main_title: Optional pre-generated main title
            sub_title: Optional pre-generated sub title

        Returns:
            Path to generated thumbnail or None
        """
        frame_path = Path(frame_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if not frame_path.exists():
            logger.error(f"Frame not found: {frame_path}")
            return None

        # Generate titles if not provided
        if not main_title or not sub_title:
            if self.enabled:
                logger.info("Generating clickbait titles...")
                main_title, sub_title = await self.generate_clickbait_title(title, subtitles)
            else:
                main_title = main_title or "ç²¾å½©å…§å®¹"
                sub_title = sub_title or "ä¸å®¹éŒ¯éŽ"

        logger.info(f"Titles: {main_title} / {sub_title}")

        # Add text overlays
        logger.info("Adding text overlays...")
        final_image = self.add_text_overlay(frame_path, main_title, sub_title)

        # Save final image
        if not filename:
            content_hash = hashlib.md5(f"{title}{main_title}".encode()).hexdigest()[:8]
            filename = f"thumbnail_{content_hash}.png"

        output_path = output_dir / filename
        with open(output_path, "wb") as f:
            f.write(final_image)

        logger.info(f"Generated thumbnail from frame: {output_path}")
        return output_path

    async def generate_for_timeline(
        self,
        title: str,
        subtitles: List[dict],
        video_path: Path,
        output_dir: Path,
        filename: Optional[str] = None,
        timestamp: Optional[float] = None,
        main_title: Optional[str] = None,
        sub_title: Optional[str] = None,
    ) -> Optional[Path]:
        """Generate a YouTube-style thumbnail for a timeline.

        Args:
            title: Video title
            subtitles: List of subtitle dicts with 'start', 'end', 'en' keys
            video_path: Path to source video
            output_dir: Directory to save thumbnail
            filename: Optional filename
            timestamp: Optional specific timestamp for frame extraction
            main_title: Optional pre-specified main title
            sub_title: Optional pre-specified sub title

        Returns:
            Path to generated thumbnail or None
        """
        if not self.enabled:
            logger.warning("Thumbnail generation disabled (no LLM API key)")
            return None

        video_path = Path(video_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if not video_path.exists():
            logger.error(f"Video file not found: {video_path}")
            return None

        # Step 1: Get timestamp (use provided or analyze for best moment)
        if timestamp is not None:
            logger.info(f"Using user-specified timestamp: {timestamp}s")
        else:
            logger.info("Analyzing emotional moments...")
            timestamp, reason = await self.analyze_emotional_moments(subtitles)

        # Step 2: Generate clickbait titles (if not provided)
        if not main_title or not sub_title:
            logger.info("Generating clickbait titles...")
            gen_main, gen_sub = await self.generate_clickbait_title(title, subtitles)
            main_title = main_title or gen_main
            sub_title = sub_title or gen_sub
        logger.info(f"Titles: {main_title} / {sub_title}")

        # Step 3: Extract frame from video
        logger.info(f"Extracting frame at {timestamp}s...")
        frame_path = output_dir / "temp_frame.jpg"
        frame_result = self.extract_frame(video_path, timestamp, frame_path)

        if not frame_result:
            # Fallback: try at 10 seconds
            logger.warning("Frame extraction failed, trying fallback at 10s...")
            frame_result = self.extract_frame(video_path, 10.0, frame_path)

        if not frame_result:
            logger.error("Failed to extract frame from video")
            return None

        # Step 4: Add text overlays
        logger.info("Adding text overlays...")
        final_image = self.add_text_overlay(frame_path, main_title, sub_title)

        # Clean up temp frame
        try:
            frame_path.unlink()
        except Exception:
            pass

        # Save final image
        if not filename:
            content_hash = hashlib.md5(f"{title}{main_title}{timestamp}".encode()).hexdigest()[:8]
            filename = f"thumbnail_{content_hash}.png"

        output_path = output_dir / filename
        with open(output_path, "wb") as f:
            f.write(final_image)

        logger.info(f"Generated thumbnail from video frame: {output_path}")
        return output_path
